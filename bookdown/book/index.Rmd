---
title: "Captian RHub meets MobyR"
author: "Stefan Küthe"
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    number_sections: false
    split_by: section
    mathjax: null
    css: include/fry.css
---
```{r, echo=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  eval = FALSE
)
```

# Build, Ship and Run Shiny Data Science, Anywhere!

```{r, echo=FALSE, eval=TRUE, out.width="40%"}
knitr::include_graphics("pix/rocker.png")
```

# Docker?

```{r, echo=FALSE, eval=TRUE, out.width="70%"}
knitr::include_graphics("pix/containers.png")
```

## Containers versus Virtual Machines

```{r, echo=FALSE, eval=TRUE, out.width="40%", out.extra='style="float: left;"'}
knitr::include_graphics("pix/docker-vs-vm_vm.png")
knitr::include_graphics("pix/docker-vs-vm_docker.png")
```

<div style="clear: both;"></div>


## Containers together with Virtual Machines

```{r, echo=FALSE, eval=TRUE, out.width="70%"}
knitr::include_graphics("pix/containers-vms-together.png")
```

## Installation

Ubuntu

```{bash}
$ apt-get install docker.io
```

MAC, Windows, other Linuxes, ...

- https://www.docker.com/community-edition

# Images

An __image__ is a set of layers as defined in the `Dockerfile`.

_"An __image__ is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software,
including the code, a runtime, libraries, environment variables, and config files."_

```{bash, eval=FALSE}
# Search for an image
$ docker search rocker

# Pull an image from the hub
$ docker pull rocker/shiny

# List local images
$ docker images
```

## Docker Hub

https://hub.docker.com

### Programming langues

- r-base
- python
- nodejs
- golang
- julia
- ...

### Databases

- mongodb
- postgresql
- mysql
- neo4j
- ...

### Webservers

- nginx
- httpd
- tomcat
- ...

### OSs

- ubuntu
- alpine
- centos
- ...

### ...

- hello-world
- ...

```{r, echo=FALSE, eval=TRUE}
#knitr::include_graphics("pix/docker-hub.png")
```

## Rocker Hub on Docker Hub

```{r, echo=FALSE, eval=TRUE,  out.width="20%"}
knitr::include_graphics("pix/rocker.png")
```

- https://hub.docker.com/r/rocker/
- https://github.com/rocker-org/rocker

Images

- rocker/r-base
- rocker/shiny
- rocker/tidyverse
- rocker/rstudio
- rocker/geospatial
- rocker/r-ver
- ...

## Automatic builds

- Github + Dockerhub

# Containers

A __container__ is an instance of an __image__.

_"A __container__ is a runtime instance of an __image__ - what the __image__ becomes in memory when actually executed.
It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so."_

```{bash, eval=FALSE}
# Start a container
$ docker run -p 3838:3838 -v /data:/data -d rocker/shiny

# -p ~ publish port to the world
# -d ~ run in detached mode
# -v ~ mount host volume in the container

# List running container
$ docker ps

# List stopped container as well
$ docker ps -a
```

# Images and layers

```{r, echo=FALSE, eval=TRUE}
knitr::include_graphics("pix/container-layers.jpg")
```

- A Docker image is built up from a series of layers.
- Each layer represents an instruction in the image’s `Dockerfile`.
- Each layer except the very last one is read-only.

# Containers and layers

```{r, echo=FALSE, eval=TRUE}
knitr::include_graphics("pix/sharing-layers.jpg")
```

- The major difference between a container and an image is the top writable layer.
- All writes to the container that add new or modify existing data are stored in this writable layer.
- When the container is deleted, the writable layer is also deleted.
- The underlying image remains unchanged.

# Container size on disk

```{bash}
$ docker ps -s
```

- __size:__ disk space used for the writable layer
- __virtual size:__ disk space used for the read-only image data used by the container

# Dockerfile

```{bash, eval=FALSE}
FROM rocker/r-base
LABEL maintainer="stefan kuethe <crazycapivara@gmail.com>"
RUN install2.r rmarkdown formatR bookdown
ADD ./book /book
WORKDIR /book
RUN apt-get update && apt-get install pandoc -y \
        && rm -rf /var/lib/apt/lists/*

CMD ["r", "render_book.R"]
```

## Build and run

```{bash}
$ docker build -t "stkuethe/rbook:v0.1" .

$ docker run -it --rm stkuethe/rbook:v0.1
```

## Containerit

Create a `Dockerfile` with the R package `containerit`

```{r, eval=FALSE}
devtools::install_github("r-hub/sysreqs")
devtools::install_github("o2r-project/containerit")

library(containerit)

dockerfile(from = sessionInfo()) %>%
  write("Dockerfile")
```

## Containerit output

```{bash, eval=FALSE}
FROM rocker/r-ver:3.4.1
LABEL maintainer="stkuethe"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 && apt-get install -y git-core \
	pandoc \
	pandoc-citeproc
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "Rcpp", ... "jsonlite"]
WORKDIR /payload/
CMD ["R"]

```

# Docker hierarchy

- Container:
    - define it with a `Dockerfile`
- Service:
    - combine, scale and balance containers: `docker-compose.yml` 
- Swarm:
    - dockerized cluster with a manager and workers: `docker swarm`, `kubernetes`, `rancher`, ...
- Stack:
    - handle services 


# Workflow ???

```
Git repo
========
- scripts/
- Dockerfile

$ git pull
$ docker build ...
$ docker run ...
```

# Docker CLI

```{bash, eval=FALSE}

# Search a registry for images, defaults to the docker hub
$ docker search

# Pull an image from a registry
$ docker pull

# Push an image to a registry
$ docker push

# List local images
$ docker images

# Remove local image
$ docker rmi

# Build an image from a Dockerfile
$ docker build

# Run a new container
$ docker run

# Stop running container
$ docker stop

# Start a stopped container
$ docker start

# Restart a running container
$ docker restart

# Remove stopped container
$ docker rm

# List containers
$ docker ps

# Fetch the logs of a container
$ docker logs

# Run a command in a running container
$ docker exec

# Copy files/folders between a container and the local filesystem
$ docker cp

# Return low-level information on Docker objects
$ docker inspect 
```

# Pipelines

Combine different programming languages ...

```{bash}
#!/bin/sh
docker run --rm -it -v `pwd`/scripts:/scripts julia julia /scripts/random.jl
docker run --rm -it -v `pwd`/scripts:/scripts rocker/r-base r /scripts/multiply.R
docker run --rm -it -v `pwd`/scripts:/scripts continuumio/miniconda3 python /scripts/print_that.py
```

## Julia script

```{bash}
# random.jl
m = rand(1:10, 10, 10)
println(m)
writecsv("/scripts/random.csv", m)
```

## R script

```{r}
# multiply.R
df <- read.csv("/scripts/random.csv", header = FALSE)
df <- df * 0.3 + 2
print(df)
write.csv(df, "/scripts/random_update.csv")
```

## Python script

```{python}
# print_that.py
import csv

with open("/scripts/random_update.csv") as f:
  reader = csv.reader(f)
  for row in reader:
    print(row)
```

# Networks

```{r, echo=FALSE, eval=TRUE}
knitr::include_graphics("pix/bridge_network.png")
```

```
$ docker network create futurama
$ docker run -d --network futurama --name postgres postgres:9.5.6-alpine
$ docker network inspect futurama | jq ".[].Containers"
```

```{r, echo=FALSE, eval=TRUE}
knitr::include_graphics("pix/network_access.png")
```

```
$ docker network create futurama
$ docker run -d --network futurama -p 8787:8787 futurama rocker/rstudio

$ docker run -it --rm --network futurama alpine ping -c 2 postgres 
```

# Docker Compose

_Compose is a tool for defining and running multi-container Docker applications._

## Config file

Compatibility matrix

- https://docs.docker.com/compose/compose-file/

Version 2

- https://docs.docker.com/compose/compose-file/compose-file-v2/

```{bash, eval=FALSE}
# docker-compose.yml

version: "2"

services:
  minicran:
    image: crazycapivara/minicran
    volumes:
      - ./scripts:/scripts
      - ./repo:/miniCRAN
    command: r /scripts/create_repo.R
  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./repo:/usr/share/nginx/html
```

## Minicran script

```{r, eval=FALSE}
# create_repo.R

library(miniCRAN)

pkgs <- c("magrittr", "dplyr")
pkgList <- pkgDep(pkgs, suggests = FALSE)
CRAN_mirror <- "https://mran.microsoft.com/snapshot/2017-08-01"
makeRepo(pkgList, path = "/miniCRAN", repos = CRAN_mirror, type=c("source", "win.binary"))
```

## Start and stop services

```{bash}
# start services
$ docker-compose up -d

# stop services
$ docker-compose down
```

# Scale and balance that

## Load Balancer ~ haproxy

```{bash, eval=FALSE}
# docker-compose.yml

version: "2"
services:
  shiny:
    image: rocker/shiny
  lb:
    image: dockercloud/haproxy
    ports:
      - "5080:80"
      - "1936:1936"
    links:
      - shiny
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
```

## Run and scale

```{bash}
docker-compose up -d \
  && docker-compose scale shiny=3
```

# Some more use cases/examples

- neo4j
- h2oai
- tensorflow
- REST API using plumber
- CRAN stats with mongodb and metabase
- bookdown

## neo4j

### Dockerfile

```{bash}
FROM rocker/rstudio
LABEL maintaner="stkuethe <crazycapivara@gmail.com>"
RUN install2.r RNeo4j
ADD ./scripts /scripts
WORKDIR /scripts
```

### Script

```{r}
# rstudio_pkgs.R
library(RNeo4j)

## --- some helpers
add_relation <- function(x, y, relation) {
  from_node <- getOrCreateNode(graph, "rpackage", name = x)
  to_node <- getOrCreateNode(graph, "rpackage", name = y)
  createRel(from_node, relation, to_node)
}

add_pkg_deps <- function(pkg, deps, relation) {
  for (dep in deps) {
    add_relation(pkg, dep, relation)
    cat(sprintf("Added (%s) -[:%s]-> (%s)\n", pkg, relation, dep))
  }
}

## --- config
rstudio_pkgs <- c("magrittr", "tidyverse", "shiny", "rmarkdown",
             "ggplot2", "knitr", "tidyr", "readr", "readxl", "dplyr", "stringr")
relations <- c("Imports", "Suggests")
deps <- lapply(relations, function(relation) {
  tools::package_dependencies(rstudio_pkgs, which = relation)
})

## --- setup graph
graph <- RNeo4j::startGraph("neo4j:7474/db/data", "neo4j", "bender")
clear(graph, FALSE)
addConstraint(graph, "rpackage", "name")
cat("graph initialized\n")

## --- main loop
for (i in 1:length(relations)) {
  for (pkg in rstudio_pkgs) {
    add_pkg_deps(pkg, deps[[i]][[pkg]], toupper(relations[i]))
  }
}
cat("done\n")			

## ------------------------

cat("Test db\n")
argv <- commandArgs(TRUE)

dep <- ifelse(!is.na(argv[1]), argv[1], "jsonlite")
query <- sprintf('MATCH (n) -[:IMPORTS]-> (dep {name: "%s"}) RETURN n.name AS pkg, "imports" AS relation, dep.name AS dep', dep)
res <- cypher(graph, query)
print(res)

pkg <- ifelse(!is.na(argv[2]), argv[2], "readxl")
query <- sprintf('MATCH (pkg {name: "%s"}) -[r]-> (n) RETURN pkg.name AS pkg, type(r) AS rel, n.name AS dep', pkg)
res <- cypher(graph, query)
print(res)
```

### Docker compose

```{bash}
version: "2"

services:
  neo4j:
    image: neo4j
    environment:
      - NEO4J_AUTH=neo4j/bender
    ports:
      - "7474:7474"
      - "7687:7687"
  terminal:
    build: .
    volumes:
      - ./scripts:/scripts
    depends_on:
      - neo4j
    command: ["./wait-for-it.sh", "neo4j:7474", "--", "Rscript", "rstudio_pkgs.R", "Rcpp", "dplyr"]
```

## h2oai

### Dockerfiles

```{bash}
$ wget https://raw.githubusercontent.com/h2oai/h2o-3/master/Dockerfile

# Dockerfile.rstudio
FROM rocker/rstudio
LABEL maintainer="<crazycapivara@gmail.com>"
RUN install2.r h2o
ADD ./scripts /home/rstudio/scripts
RUN chown -R rstudio:rstudio /home/rstudio/scripts
```

### Docker compose

```{bash}
# docker-compose.yml
version: "2"

services:
  h2oai:
    build: .
    command:  java -Xmx4g -jar /opt/h2o.jar
    ports:
      - "54321:54321"
  rstudio:
    build:
      context: .
      dockerfile: Dockerfile.rstudio
    ports:
      - "9797:8787" 

$ docker-compose up -d
```

### Script

```{r}
# use_h2oai.R
suppressPackageStartupMessages(library(h2o))

# package version should match server version
try(h2o.init("h2oai"), silent = TRUE)

# show available data frames on the server
h2o.ls()

# add data
cat("Add data\n")
iris_train <- as.h2o(iris[, 1:4], "iris_train")
iris_validate <- as.h2o(iris, "iris_validate")

# show available data frames on the server
h2o.ls()

# build the model
cat("Build the model\n")
iris_kmeans <- h2o.kmeans(iris_train, k = 3, model_id = "iris_kmeans", init = "Random")

# predict and show result
cat("Predict that\n")
iris_predict <- h2o.predict(iris_kmeans, iris_validate)
res <- as.data.frame(h2o.cbind(iris_validate, iris_predict))
print(res)
```

## tensorflow

### Run RStudio and TensorFlow

```{bash}
docker run -d --name tensor_flow -p 8686:8787 -v `pwd`/scripts:/home/rstudio/scripts earthlab/r-tensorflow
```

### Scripts

Test installation

```{r}
# hello_world.R
library(tensorflow)

sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
```

Real world example

```{r}
# example.R
library(tensorflow)

# Create 100 phony x, y data points, y = x * 0.1 + 0.3
x_data <- runif(100, min = 0, max = 1)
y_data <- x_data * 0.1 + 0.3

# Try to find values for W and b that compute y_data = W * x_data + b
# (We know that W should be 0.1 and b 0.3, but TensorFlow will
# figure that out for us.)
W <- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0))
b <- tf$Variable(tf$zeros(shape(1L)))
y <- W * x_data + b

# Minimize the mean squared errors.
loss <- tf$reduce_mean((y - y_data) ^ 2)
optimizer <- tf$train$GradientDescentOptimizer(0.5)
train <- optimizer$minimize(loss)

# Launch the graph and initialize the variables.
sess = tf$Session()
sess$run(tf$initialize_all_variables())

# Fit the line (Learns best fit is W: 0.1, b: 0.3)
for (step in 1:201) {
  sess$run(train)
  if (step %% 20 == 0)
    cat(step, "-", sess$run(W), sess$run(b), "\n")
}
```

## plumber

### Dockerfile

```{bash}
FROM rocker/r-base
LABEL maintainer="Stefan Kuethe <crazycapivara@gmail.com>"
RUN apt-get update -qq && apt-get install -y libxml2-dev
RUN install2.r plumber xml2 base64enc
ADD ./scripts /endpoints
EXPOSE 8000
ENTRYPOINT ["R", "-e", "pr <- plumber::plumb(commandArgs()[4]); pr$run(host = '0.0.0.0', port = 8000, swagger = TRUE)"]
CMD ["/endpoints/rstudio_rss-feed.R"]
```

### Endpoints

RStudio rss feed

```{r}
# rstudio_rss-feed.R
library(xml2)
library(magrittr)

rss_feed <- "https://blog.rstudio.com/index.xml"

#* @get /rstudio_rss_feed
rstudio_rss_feed <- function() {
  rss <- read_xml(rss_feed)
  items <- xml_find_all(rss, ".//item")
  titles <- xml_find_all(items, ".//title") %>%
    xml_text()
  links <- xml_find_all(items, ".//link") %>%
    xml_text()
  data.frame(header = titles, link = links)
}
```

Images

```{r}
library(base64enc)

#* @get /plot_that
#* @png
plot_that <- function() {
  x <- seq(1, 10, 0.1)
  y <- sin(x)
  plot(x, y, type = "l")
}

#* @get /plot_base64
plot_base64 <- function() {
  x <- seq(1, 10, 0.1)
  y <- sin(x)
  tmp <- tempfile()
  png(tmp)
  plot(x, y, type = "l")
  dev.off()
  paste("data:image/png;base64,", base64encode(tmp))
}
```

Blog

```{r}
library(xml2)
library(magrittr)

rss_feed <- "https://blog.rstudio.com/index.xml"

#* @get /rstudio_rss_feed
rstudio_rss_feed <- function() {
  rss <- read_xml(rss_feed)
  items <- xml_find_all(rss, ".//item")
  titles <- xml_find_all(items, ".//title") %>%
    xml_text()
  links <- xml_find_all(items, ".//link") %>%
    xml_text()
  data.frame(header = titles, link = links, stringsAsFactors = FALSE)
}

library(tm)

#* @get /rocket_science/<count>
rocket_science <- function(headers = NULL, count = 2, lang= "english") {
  if (is.null(headers)) {
    headers <- rstudio_rss_feed()$header
  }
  docs <- Corpus(VectorSource(enc2native(headers))) %>%
    tm_map(content_transformer(tolower)) %>%
    tm_map(removePunctuation) %>%
    tm_map(removeWords, enc2native(stopwords(lang))) %>%
    tm_map(removeNumbers) %>%
    tm_map(stripWhitespace)
  tdm <- TermDocumentMatrix(docs)
  findFreqTerms(tdm, as.integer(count))
}

blog <- "https://blog.eoda.de"

eoda_blog <- function(page = 1) {
  xml <- sprintf("%s/page/%i/", blog, page) %>%
    read_html()
  items <- xml_find_all(xml, ".//article")
  xml_find_all(items, ".//header/h2") %>%
    xml_text()
}

#* @get /eoda_blog
eoda_blog_ <- function(last_page = 3) {
  lapply(1:last_page, eoda_blog) %>%
    unlist()
}

#* @get /blog_that
blog_that <- function(count = 3) {
  rocket_science(eoda_blog_(), count = count, lang = "de")
}
```

### Run and test

```{bash}
$ docker run -d -p 8011:8000 --name plumber \
    -v `pwd`/scripts:/endpoints crazycapivara/plumber r /endpoints/serve_that.R

curl -s http://localhost:8011/blog_that?count=4 | jq
```

### Use in other apps

```{python}
# app.py
from flask import Flask, render_template
import requests

api = "http://plumber:8000/rstudio_news"

def get_news():
   response = requests.get(api)
   data = response.json()
   response.close()
   return data

app = Flask(__name__)

@app.route("/")
def hello():
   return render_template("rstudio_news.html", news = get_news())

if __name__ == "__main__":
   app.run(host = "0.0.0.0", debug = True)

```

```{bash}
# docker-compose.yml
version: "2"

services:
  plumber:
    image: crazycapivara/plumber:rstudio_news
  flask:
    image: crazycapivara/flask
    command: app.py
    ports:
      - "5005:5000"
```

## CRAN stats with metabase and mongodb

### Dockerfile

```{bash}
FROM rocker/rstudio
LABEL maintainer="<crazycapivara@gmail.com>"
RUN apt-get update \
      && apt-get install -y libssl-dev libsasl2-dev
RUN install2.r mongolite remotes httr \
      && installGithub.r metacran/cranlogs
ADD ./scripts /home/rstudio/scripts
```

### Docker Compose

```{bash}
version: "2"

services:
  rstudio:
    build: .
    ports:
      - "8787:8787"
  metabase:
    image: metabase/metabase
    ports:
      - "3015:3000"
  mongodb:
    image: mongo
    ports:
      - "27020:27017"
```

### Script

```{r}
# dl_stats.R
library(cranlogs)
library(mongolite)

argv <- commandArgs(TRUE)

# get logs
cat("Fetch logs\n")
pkgs <- c("shiny", "shinydashboard", "rmarkdown", "leaflet")
if(!is.na(argv[1])) {
  pkgs <- argv[1]
}
print(pkgs)
logs <- cran_downloads(pkgs, when = "last-month")
print(tail(logs))

# write logs to db
db <- "rstudio"
collection <- "cranlogs"

cat("insert data\n")
conn <- mongo(collection, db = db, url="mongodb://mongodb")
eat_msg <- conn$insert(logs)
cat("done\n")
```
### Add data

```{bash}
$ docker run -it --rm -v `pwd`/scripts:/scripts \
    --network futurama example_rstudio Rscript /scripts/dl_stats.R ggplot
```

## bookdown 

### Dockerfile

```{bash}
FROM rocker/r-base
LABEL maintainer="crazycapivara@gmail.com"
RUN install2.r rmarkdown formatR bookdown
ADD ./book /book
WORKDIR /book
RUN apt-get update && apt-get install pandoc -y \
        && rm -rf /var/lib/apt/lists/*
```

### Render book

```{bash}
# render_book.R
library(bookdown)

render_book(".")
```

```{bash}
$ docker run -it --rm \
    -v `pwd`/book:/book \
    crazycapivara/r-base-bookdown r render_book.R
```

### Serve book

```{bash}
version: "2"
services:
  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./book/_book:/usr/share/nginx/html:ro
```

# Continious Integration

```{r, echo=FALSE, eval=TRUE}
#knitr::include_graphics("pix/gitlab-pipelines.png")
knitr::include_graphics("pix/gitlab-pipelines2.png")
```

## Gitlab CI

https://about.gitlab.com/

All in one

### Gitlab Container

```{bash}
# Gitlab
version: "2"

services:
  gitlab:
    image: "gitlab/gitlab-ce:latest"
    restart: always
    hostname: "172.17.0.1"
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url "http://172.17.0.1:9090"
        gitlab_rails["gitlab_shell_ssh_port"] = 2224
    ports:
      - "9090:9090"
      - "2224:22"
    volumes:
      - "./config:/etc/gitlab"
      - "./logs:/var/log/gitlab"
      - "./data:/var/opt/gitlab"
```

### Gitlab runner

#### Start runner

```{bash}
#!/bin/sh
docker run -d --name gitlab-runner \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v `pwd`/gitlab-runner/config:/etc/gitlab-runner \
  gitlab/gitlab-runner:latest
```

#### Register runner

```{bash}
$ docker exec -it gitlab-runner gitlab-runner register
```

#### Config

```{bash}
# config.toml

[[runners]]
  name = "bender"
  url = "http://"172.17.0.1:9090/"
  token = "3bd3d65fd0fe66bcece672a2eb7603"
  executor = "docker"
  [runners.docker]
    tls_verify = false
    image = "rocker/r-base"
    privileged = false
    disable_cache = false
    volumes = ["/www/data_science:/share_that", "/cache"]
    shm_size = 0
    pull_policy = "never"
  [runners.cache]
```

### Pipeline

```{bash}
# .gitlab-ci.yml

stages:
  - julia
  - r
  - deploy

julia:
  stage: julia
  image: julia
  artifacts:
    paths:
      - that.csv
    expire_in: 5 minutes
  script:
    - julia create_csv.jl

r:
  stage: r
  image: rocker/r-base
  script:
    - Rscript -e "df <- read.csv('that.csv'); do_science(df)"

deploy:
  stage: deploy
  image: alpine
  script:
    - cp that.csv /www/public
```

## Drone

https://drone.io/

Lightweight

```{r, echo=FALSE, eval=TRUE, out.width="20%"}
knitr::include_graphics("pix/droneio.png")
#knitr::include_graphics("pix/gogs.png")
```

Integrations:

- Gogs
- GitLab
- Github
- Bitbucket
- Gitea


### Gogs container

```{bash, eval=FALSE}
# start gogs
$ docker run --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs
```

### Drone server and agent

```{bash}
version: '2'
services:
  drone-server:
    image: drone/drone:0.7
    ports:
      - 80:8000
    volumes:
      - /var/lib/drone:/var/lib/drone/
    restart: always
    environment:
      - DRONE_OPEN=true
      - DRONE_HOST=${DRONE_HOST}
      #- DRONE_GITHUB=true
      #- DRONE_GITHUB_CLIENT=${DRONE_GITHUB_CLIENT}
      #- DRONE_GITHUB_SECRET=${DRONE_GITHUB_SECRET}
      - DRONE_GOGS=true
      - DRONE_GOGS_URL=http://gogs.mycompany.com

  drone-agent:
    image: drone/drone:0.7
    command: agent
    restart: always
    depends_on:
      - drone-server
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - DRONE_SERVER=ws://drone-server:8000/ws/broker
      - DRONE_SECRET=${DRONE_SECRET}
```

### Pipeline

```{bash}
# .drone.yml

pipeline:
  build:
    image: rocker/r-base
      commands:
      - cd /scripts/
      - Rscript run_tests.R
```

## Concourse

http://www.concourse.ci/

Lightweight

### Docker compose

```{bash}
Version: '3'

services:
  concourse-db:
    image: postgres:9.5
    environment:
      POSTGRES_DB: concourse
      POSTGRES_USER: concourse
      POSTGRES_PASSWORD: changeme
      PGDATA: /database

  concourse-web:
    image: concourse/concourse
    links: [concourse-db]
    command: web
    depends_on: [concourse-db]
    ports: ["8080:8080"]
    volumes: ["./keys/web:/concourse-keys"]
    restart: unless-stopped # required so that it retries until conocurse-db comes up
    environment:
      CONCOURSE_BASIC_AUTH_USERNAME: concourse
      CONCOURSE_BASIC_AUTH_PASSWORD: changeme
      CONCOURSE_EXTERNAL_URL: "${CONCOURSE_EXTERNAL_URL}"
      CONCOURSE_POSTGRES_HOST: concourse-db
      CONCOURSE_POSTGRES_USER: concourse
      CONCOURSE_POSTGRES_PASSWORD: changeme
      CONCOURSE_POSTGRES_DATABASE: concourse

  concourse-worker:
    image: concourse/concourse
    privileged: true
    links: [concourse-web]
    depends_on: [concourse-web]
    command: worker
    volumes: ["./keys/worker:/concourse-keys"]
    environment:
      CONCOURSE_TSA_HOST: concourse-web
```

### Tasks

```{bash}
# task.yml
platform: linux

image_resource:
  type: docker-image
  source:
    repository: rocker/r-base

inputs:
  - name: bender

run:
  path: ./bender/build.sh

```

```{bash}
# build.sh
#!/bin/sh
set -e -x

install2.r magrittr

Rscript -e "library(magrittr);iris %>% head() %>% print()"
```

```{bash}
$ fly -t example execute -c ci/task.yml
```

# Cluster?

## Docker Swarm

https://docker.com

## Kubernetes

https://kubernetes.io/

## Rancher

http://rancher.com/

## ...

# Orchestrierung ~ Docker Swarm

Seit Version 1.12 bietet Docker eine integrierte Cluster-Implementierung an.

```{bash, eval=FALSE}
$ docker swarm
$ docker node
$ docker service

# Create a manager (node)
$ docker swarm init --advertise-addr 192.168.99.100

# Generate token needed to join manager
$ docker swarm join-token worker

# Add a worker (node)
$ docker swarm join --token [...] 192.168.99.100:2377

# List nodes
$ docker node ls

# Deploy a service
$ docker service create --replicas 1 --name helloworld alpine ping docker.com
```

# Orchestrierung ~ Rancher

```{r, echo=FALSE, eval=TRUE, out.width="40%"}
knitr::include_graphics("pix/rancher.png")
```

http://rancher.com/

## Features

- Web-GUI
- can manage
    - Docker Swarm
    - Kubernetes

## Installation

```{bash, eval=FALSE}
## Management node (server)
$ docker run -d --restart=unless-stopped -p 8080:8080 rancher/server 

## Add workers (agents)
$ docker run -d [...] rancher/agent [...]token
```

# Orchestrierung ~ Kubernetes (Google)

```{r, echo=FALSE, eval=TRUE, out.width="40%"}
knitr::include_graphics("pix/kubernetes.png")
```

https://kubernetes.io/

