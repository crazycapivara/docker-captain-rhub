[
["index.html", "Captian RHub meets MobyR Build, Ship and Run Shiny Data Science, Anywhere!", " Captian RHub meets MobyR Stefan Küthe Build, Ship and Run Shiny Data Science, Anywhere! "],
["docker.html", "Docker?", " Docker? "],
["about.html", "About", " About Programming Language: GO Operating System Level Virtualization # Spin up 100 containers $ time for i in $(seq 1 100); do docker run -d -P --name nginx_$i nginx:alpine; done ... real 0m56.476s user 0m1.364s sys 0m0.860s # Stop and remove ... $ for i in $(seq 1 100); do docker stop nginx_$i; done $ for i in $(seq 1 100); do docker rm nginx_$i; done "],
["containers-versus-virtual-machines.html", "Containers versus Virtual Machines", " Containers versus Virtual Machines "],
["containers-together-with-virtual-machines.html", "Containers together with Virtual Machines", " Containers together with Virtual Machines "],
["installation.html", "Installation", " Installation Ubuntu $ apt-get install docker.io MAC, Windows, other Linuxes, … https://www.docker.com/community-edition "],
["images.html", "Images", " Images An image is a set of layers as defined in the Dockerfile. “An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files.” # Search for an image $ docker search rocker # Pull an image from the hub $ docker pull rocker/shiny # List local images $ docker images "],
["docker-hub.html", "Docker Hub", " Docker Hub https://hub.docker.com Programming langues r-base python nodejs golang julia … Databases mongodb postgresql mysql neo4j … Webservers nginx httpd tomcat … OSs ubuntu alpine centos … … hello-world … "],
["offical-images.html", "Offical images", " Offical images https://hub.docker.com/explore/ Ensure that security updates are applied in a timely manner. Provide essential base OS repositories. Use best practices and and provide clear documentation Offical R image https://store.docker.com/images/r-base https://docs.docker.com/samples/library/r-base/ "],
["rocker-hub-on-docker-hub.html", "Rocker Hub on Docker Hub", " Rocker Hub on Docker Hub https://hub.docker.com/r/rocker/ https://github.com/rocker-org/rocker Images rocker/r-base rocker/shiny rocker/tidyverse rocker/rstudio rocker/geospatial rocker/r-ver … "],
["manual-builds.html", "Manual builds", " Manual builds # Enter bash inside a container $ docker run -it --name mobyr rocker/r-base /bin/bash # Do some stuff ... mobyr/ $ install2.r magrittr RNeo4j # Leave container mobyr/ $ exit # Commit changes $ docker commit -m &quot;Add magrittr and RNeo4j&quot; mobyr kuethe/mobyr:0.1 # Push image to Dockerhub $ docker login $ docker push mobyr Is this the way we should create images? Nope! Use a Dockerfile! "],
["automatic-builds.html", "Automatic builds", " Automatic builds Dockerhub + Github "],
["deploy-your-own-registry.html", "Deploy your own registry", " Deploy your own registry A registry is an instance of the registry image, and runs within Docker. # Start registry on port 5000 $ docker run -d \\ -p 5000:5000 \\ -e REGISTRY_HTTP_ADDR=0.0.0.0:5000 --restart=always \\ --name registry registry:2 Without cert, ups … # /etc/docker/damon.json { &quot;insecure-registries&quot;: [&quot;my-registry.com:5000&quot;] } $ docker push my-registry.com/mobyr "],
["containers.html", "Containers", " Containers A container is an instance of an image. “A container is a runtime instance of an image - what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so.” # Start a container $ docker run -p 3838:3838 -v /data:/data -d rocker/shiny # -p ~ publish port to the world # -d ~ run in detached mode # -v ~ mount host volume in the container # List running container $ docker ps # List stopped container as well $ docker ps -a "],
["images-and-layers.html", "Images and layers", " Images and layers A Docker image is built up from a series of layers. Each layer represents an instruction in the image’s Dockerfile. Each layer except the very last one is read-only. "],
["containers-and-layers.html", "Containers and layers", " Containers and layers The major difference between a container and an image is the top writable layer. All writes to the container that add new or modify existing data are stored in this writable layer. When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged. "],
["container-size-on-disk.html", "Container size on disk", " Container size on disk $ docker ps -s size: disk space used for the writable layer virtual size: disk space used for the read-only image data used by the container "],
["dockerfile.html", "Dockerfile", " Dockerfile FROM rocker/r-base LABEL maintainer=&quot;stefan kuethe &lt;crazycapivara@gmail.com&gt;&quot; RUN install2.r rmarkdown formatR bookdown COPY ./book /book WORKDIR /book RUN apt-get update &amp;&amp; apt-get install pandoc -y \\ &amp;&amp; rm -rf /var/lib/apt/lists/* CMD [&quot;r&quot;, &quot;render_book.R&quot;] "],
["build-and-run.html", "Build and run", " Build and run $ docker build -t &quot;kuethe/gitbook:0.1&quot; . $ docker run -it --rm kuethe/gitbook:0.1 "],
["containerit.html", "Containerit", " Containerit Create a Dockerfile with the R package containerit devtools::install_github(&quot;r-hub/sysreqs&quot;) devtools::install_github(&quot;o2r-project/containerit&quot;) library(containerit) dockerfile(from = sessionInfo()) %&gt;% write(&quot;Dockerfile&quot;) "],
["containerit-output.html", "Containerit output", " Containerit output FROM rocker/r-ver:3.4.1 LABEL maintainer=&quot;kuethe&quot; RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\ &amp;&amp; apt-get install -y git-core \\ pandoc \\ pandoc-citeproc RUN [&quot;install2.r&quot;, &quot;-r &#39;https://cloud.r-project.org&#39;&quot;, &quot;Rcpp&quot;, ... &quot;jsonlite&quot;] WORKDIR /payload/ CMD [&quot;R&quot;] "],
["data-in-docker.html", "Data in Docker", " Data in Docker volumes: stored in a part of the host filesystem which is managed by Docker bind mounts: may be stored anywhere on the host system tmpfs mounts: stored in the host system’s memory only, and are never written to the host system’s filesystem "],
["bind-mounts.html", "Bind mounts", " Bind mounts $ docker run -v /scripts:/rocket-science rocker/rbase r /rocket-science/go.R "],
["volumes.html", "Volumes", " Volumes $ docker volume create --name shiny-data $ docker -v shiny-data:/srv/shiny-server rocker/shiny $ docker volume ls $ docker volume inspect shiny-data [ { &quot;Name&quot;: &quot;shiny-data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/shiny-data/_data&quot;, &quot;Labels&quot;: {}, &quot;Scope&quot;: &quot;local&quot; } ] "],
["tmpfs.html", "tmpfs", " tmpfs $ docker run --tmpfs /rocket-science -it rocker/rbase /bin/bash "],
["at-build-time.html", "At build time", " At build time COPY and ADD ADD allows &lt;src&gt; to be an URL If the &lt;src&gt; parameter of ADD is an archive in a recognised compression format, it will be unpacked. # Dockerfiles COPY /scripts /scripts ADD /scripts /scripts "],
["copy-data-from-and-to-running-containers.html", "Copy data from and to running containers", " Copy data from and to running containers # from container to local filesystem $ docker cp CONTAINER:SRC_PATH DEST_PATH # from local filesystem to container $ docker cp CONTAINER:SRC_PATH DEST_PATH "],
["networks-and-port-forwarding.html", "Networks and port forwarding", " Networks and port forwarding $ docker network create futurama $ docker run -d --network futurama --name postgres postgres:9.5.6-alpine $ docker network inspect futurama | jq &quot;.[].Containers&quot; $ docker network create futurama $ docker run -d --network futurama -p 8787:8787 futurama rocker/rstudio $ docker run -it --rm --network futurama alpine ping -c 2 postgres "],
["docker-hierarchy.html", "Docker hierarchy", " Docker hierarchy Image/Container: define it with a Dockerfile Service: combine, scale and balance containers: docker-compose.yml Swarm: dockerized cluster with a manager and workers: docker swarm, kubernetes, rancher, … Stack: handle services "],
["simple-manual-workflow.html", "Simple manual workflow ???", " Simple manual workflow ??? Git repo ======== - scripts/ - Dockerfile $ git pull $ docker build ... $ docker run ... "],
["docker-cli.html", "Docker CLI", " Docker CLI # Search a registry for images, defaults to the docker hub $ docker search # Pull an image from a registry $ docker pull # Push an image to a registry $ docker push # List local images $ docker images # Remove local image $ docker rmi # Build an image from a Dockerfile $ docker build # Run a new container $ docker run # Stop running container $ docker stop # Start a stopped container $ docker start # Restart a running container $ docker restart # Remove stopped container $ docker rm # List containers $ docker ps # Fetch the logs of a container $ docker logs # Run a command in a running container $ docker exec # Copy files/folders between a container and the local filesystem $ docker cp # Return low-level information on Docker objects $ docker inspect "],
["pipelines.html", "Pipelines", " Pipelines Combine different programming languages … # rocket_science.sh #!/bin/sh docker run --rm -it -v /scripts:/scripts julia julia /scripts/random.jl docker run --rm -it -v /scripts:/scripts rocker/r-base r /scripts/multiply.R docker run --rm -it -v /scripts:/scripts continuumio/miniconda3 python /scripts/print_that.py Maybe you want to use a cronjob to run it every 10 minutes … # crontab */10 * * * * /sbin/rocket_science.sh &gt;&gt;/var/log/cronrun "],
["julia-script.html", "Julia script", " Julia script # random.jl m = rand(1:10, 10, 10) println(m) writecsv(&quot;/scripts/random.csv&quot;, m) "],
["r-script.html", "R script", " R script # multiply.R df &lt;- read.csv(&quot;/scripts/random.csv&quot;, header = FALSE) df &lt;- df * 0.3 + 2 print(df) write.csv(df, &quot;/scripts/random_update.csv&quot;) "],
["python-script.html", "Python script", " Python script # print_that.py import csv with open(&quot;/scripts/random_update.csv&quot;) as f: reader = csv.reader(f) for row in reader: print(row) "],
["docker-compose.html", "Docker Compose", " Docker Compose Compose is a tool for defining and running multi-container Docker applications. Compose file format Docker Engine release … … 3.0 1.13.0+ … … 2.0 1.10.0+ "],
["config-file.html", "Config file", " Config file Compatibility matrix https://docs.docker.com/compose/compose-file/ Version 2 https://docs.docker.com/compose/compose-file/compose-file-v2/ # docker-compose.yml version: &quot;2&quot; services: minicran: image: crazycapivara/minicran volumes: - ./scripts:/scripts - ./repo:/miniCRAN command: r /scripts/create_repo.R nginx: image: nginx:alpine ports: - &quot;8080:80&quot; volumes: - ./repo:/usr/share/nginx/html "],
["minicran-script.html", "Minicran script", " Minicran script # create_repo.R library(miniCRAN) pkgs &lt;- c(&quot;magrittr&quot;, &quot;dplyr&quot;) pkgList &lt;- pkgDep(pkgs, suggests = FALSE) CRAN_mirror &lt;- &quot;https://mran.microsoft.com/snapshot/2017-08-01&quot; makeRepo(pkgList, path = &quot;/miniCRAN&quot;, repos = CRAN_mirror, type=c(&quot;source&quot;, &quot;win.binary&quot;)) "],
["start-and-stop-services.html", "Start and stop services", " Start and stop services # Start services $ docker-compose up -d # Stop services $ docker-compose stop # Remove services $ docker-compose down "],
["load-balancer.html", "Load balancer", " Load balancer HAProxy http://www.haproxy.org/ https://github.com/docker/dockercloud-haproxy # docker-compose.yml version: &quot;2&quot; services: shiny: image: rocker/shiny lb: image: dockercloud/haproxy ports: - &quot;5080:80&quot; - &quot;1936:1936&quot; links: - shiny volumes: - /var/run/docker.sock:/var/run/docker.sock "],
["run-and-scale.html", "Run and scale", " Run and scale docker-compose up -d \\ &amp;&amp; docker-compose scale shiny=3 Since version 2.2 file format also in docker-compose.yml services: shiny: image: rocker/shiny scale: 3 "],
["deploy.html", "Deploy", " Deploy Version 3 only only takes effect in swarm mode version: &#39;3&#39; services: redis: image: redis:alpine deploy: replicas: 6 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure "],
["some-more-examples.html", "Some more examples", " Some more examples neo4j h2oai tensorflow REST API using plumber CRAN stats with mongodb and metabase bookdown "],
["neo4j.html", "neo4j", " neo4j Dockerfile FROM rocker/rstudio LABEL maintaner=&quot;kuethe &lt;crazycapivara@gmail.com&gt;&quot; RUN install2.r RNeo4j COPY ./scripts /scripts WORKDIR /scripts Script # rstudio_pkgs.R library(RNeo4j) ## --- some helpers add_relation &lt;- function(x, y, relation) { from_node &lt;- getOrCreateNode(graph, &quot;rpackage&quot;, name = x) to_node &lt;- getOrCreateNode(graph, &quot;rpackage&quot;, name = y) createRel(from_node, relation, to_node) } add_pkg_deps &lt;- function(pkg, deps, relation) { for (dep in deps) { add_relation(pkg, dep, relation) cat(sprintf(&quot;Added (%s) -[:%s]-&gt; (%s)\\n&quot;, pkg, relation, dep)) } } ## --- config rstudio_pkgs &lt;- c(&quot;magrittr&quot;, &quot;tidyverse&quot;, &quot;shiny&quot;, &quot;rmarkdown&quot;, &quot;ggplot2&quot;, &quot;knitr&quot;, &quot;tidyr&quot;, &quot;readr&quot;, &quot;readxl&quot;, &quot;dplyr&quot;, &quot;stringr&quot;) relations &lt;- c(&quot;Imports&quot;, &quot;Suggests&quot;) deps &lt;- lapply(relations, function(relation) { tools::package_dependencies(rstudio_pkgs, which = relation) }) ## --- setup graph graph &lt;- RNeo4j::startGraph(&quot;neo4j:7474/db/data&quot;, &quot;neo4j&quot;, &quot;bender&quot;) clear(graph, FALSE) addConstraint(graph, &quot;rpackage&quot;, &quot;name&quot;) cat(&quot;graph initialized\\n&quot;) ## --- main loop for (i in 1:length(relations)) { for (pkg in rstudio_pkgs) { add_pkg_deps(pkg, deps[[i]][[pkg]], toupper(relations[i])) } } cat(&quot;done\\n&quot;) ## ------------------------ cat(&quot;Test db\\n&quot;) argv &lt;- commandArgs(TRUE) dep &lt;- ifelse(!is.na(argv[1]), argv[1], &quot;jsonlite&quot;) query &lt;- sprintf(&#39;MATCH (n) -[:IMPORTS]-&gt; (dep {name: &quot;%s&quot;}) RETURN n.name AS pkg, &quot;imports&quot; AS relation, dep.name AS dep&#39;, dep) res &lt;- cypher(graph, query) print(res) pkg &lt;- ifelse(!is.na(argv[2]), argv[2], &quot;readxl&quot;) query &lt;- sprintf(&#39;MATCH (pkg {name: &quot;%s&quot;}) -[r]-&gt; (n) RETURN pkg.name AS pkg, type(r) AS rel, n.name AS dep&#39;, pkg) res &lt;- cypher(graph, query) print(res) Docker compose version: &quot;2&quot; services: neo4j: image: neo4j environment: - NEO4J_AUTH=neo4j/bender ports: - &quot;7474:7474&quot; - &quot;7687:7687&quot; terminal: build: . volumes: - ./scripts:/scripts depends_on: - neo4j command: [&quot;./wait-for-it.sh&quot;, &quot;neo4j:7474&quot;, &quot;--&quot;, &quot;Rscript&quot;, &quot;rstudio_pkgs.R&quot;, &quot;Rcpp&quot;, &quot;dplyr&quot;] "],
["h2oai.html", "h2oai", " h2oai Dockerfiles $ wget https://raw.githubusercontent.com/h2oai/h2o-3/master/Dockerfile # Dockerfile.rstudio FROM rocker/rstudio LABEL maintainer=&quot;kuethe &lt;crazycapivara@gmail.com&gt;&quot; RUN install2.r h2o COPY ./scripts /home/rstudio/scripts RUN chown -R rstudio:rstudio /home/rstudio/scripts Docker compose # docker-compose.yml version: &quot;2&quot; services: h2oai: build: . command: java -Xmx4g -jar /opt/h2o.jar ports: - &quot;54321:54321&quot; rstudio: build: context: . dockerfile: Dockerfile.rstudio ports: - &quot;9797:8787&quot; $ docker-compose up -d Script # use_h2oai.R suppressPackageStartupMessages(library(h2o)) # package version should match server version try(h2o.init(&quot;h2oai&quot;), silent = TRUE) # show available data frames on the server h2o.ls() # add data cat(&quot;Add data\\n&quot;) iris_train &lt;- as.h2o(iris[, 1:4], &quot;iris_train&quot;) iris_validate &lt;- as.h2o(iris, &quot;iris_validate&quot;) # show available data frames on the server h2o.ls() # build the model cat(&quot;Build the model\\n&quot;) iris_kmeans &lt;- h2o.kmeans(iris_train, k = 3, model_id = &quot;iris_kmeans&quot;, init = &quot;Random&quot;) # predict and show result cat(&quot;Predict that\\n&quot;) iris_predict &lt;- h2o.predict(iris_kmeans, iris_validate) res &lt;- as.data.frame(h2o.cbind(iris_validate, iris_predict)) print(res) "],
["tensorflow.html", "tensorflow", " tensorflow Run RStudio and TensorFlow docker run -d --name tensor_flow -p 8686:8787 -v `pwd`/scripts:/home/rstudio/scripts earthlab/r-tensorflow Scripts Test installation # hello_world.R library(tensorflow) sess = tf$Session() hello &lt;- tf$constant(&#39;Hello, TensorFlow!&#39;) sess$run(hello) Real world example # example.R library(tensorflow) # Create 100 phony x, y data points, y = x * 0.1 + 0.3 x_data &lt;- runif(100, min = 0, max = 1) y_data &lt;- x_data * 0.1 + 0.3 # Try to find values for W and b that compute y_data = W * x_data + b # (We know that W should be 0.1 and b 0.3, but TensorFlow will # figure that out for us.) W &lt;- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0)) b &lt;- tf$Variable(tf$zeros(shape(1L))) y &lt;- W * x_data + b # Minimize the mean squared errors. loss &lt;- tf$reduce_mean((y - y_data) ^ 2) optimizer &lt;- tf$train$GradientDescentOptimizer(0.5) train &lt;- optimizer$minimize(loss) # Launch the graph and initialize the variables. sess = tf$Session() sess$run(tf$initialize_all_variables()) # Fit the line (Learns best fit is W: 0.1, b: 0.3) for (step in 1:201) { sess$run(train) if (step %% 20 == 0) cat(step, &quot;-&quot;, sess$run(W), sess$run(b), &quot;\\n&quot;) } "],
["plumber.html", "plumber", " plumber https://www.rplumber.io Dockerfile FROM rocker/r-base LABEL maintainer=&quot;Stefan Kuethe &lt;crazycapivara@gmail.com&gt;&quot; RUN apt-get update -qq &amp;&amp; apt-get install -y libxml2-dev RUN install2.r plumber xml2 base64enci tm COPY ./scripts /endpoints EXPOSE 8000 ENTRYPOINT [&quot;R&quot;, &quot;-e&quot;, &quot;pr &lt;- plumber::plumb(commandArgs()[4]); pr$run(host = &#39;0.0.0.0&#39;, port = 8000, swagger = TRUE)&quot;] CMD [&quot;/endpoints/rstudio_rss-feed.R&quot;] Endpoints RStudio rss feed # rstudio_rss-feed.R library(xml2) library(magrittr) rss_feed &lt;- &quot;https://blog.rstudio.com/index.xml&quot; #* @get /rstudio_rss_feed rstudio_rss_feed &lt;- function() { rss &lt;- read_xml(rss_feed) items &lt;- xml_find_all(rss, &quot;.//item&quot;) titles &lt;- xml_find_all(items, &quot;.//title&quot;) %&gt;% xml_text() links &lt;- xml_find_all(items, &quot;.//link&quot;) %&gt;% xml_text() data.frame(header = titles, link = links) } Images library(base64enc) #* @get /plot_that #* @png plot_that &lt;- function() { x &lt;- seq(1, 10, 0.1) y &lt;- sin(x) plot(x, y, type = &quot;l&quot;) } #* @get /plot_base64 plot_base64 &lt;- function() { x &lt;- seq(1, 10, 0.1) y &lt;- sin(x) tmp &lt;- tempfile() png(tmp) plot(x, y, type = &quot;l&quot;) dev.off() paste(&quot;data:image/png;base64,&quot;, base64encode(tmp)) } Blog library(xml2) library(magrittr) rss_feed &lt;- &quot;https://blog.rstudio.com/index.xml&quot; #* @get /rstudio_rss_feed rstudio_rss_feed &lt;- function() { rss &lt;- read_xml(rss_feed) items &lt;- xml_find_all(rss, &quot;.//item&quot;) titles &lt;- xml_find_all(items, &quot;.//title&quot;) %&gt;% xml_text() links &lt;- xml_find_all(items, &quot;.//link&quot;) %&gt;% xml_text() data.frame(header = titles, link = links, stringsAsFactors = FALSE) } library(tm) #* @get /rocket_science/&lt;count&gt; rocket_science &lt;- function(headers = NULL, count = 2, lang= &quot;english&quot;) { if (is.null(headers)) { headers &lt;- rstudio_rss_feed()$header } docs &lt;- Corpus(VectorSource(enc2native(headers))) %&gt;% tm_map(content_transformer(tolower)) %&gt;% tm_map(removePunctuation) %&gt;% tm_map(removeWords, enc2native(stopwords(lang))) %&gt;% tm_map(removeNumbers) %&gt;% tm_map(stripWhitespace) tdm &lt;- TermDocumentMatrix(docs) findFreqTerms(tdm, as.integer(count)) } blog &lt;- &quot;https://blog.eoda.de&quot; eoda_blog &lt;- function(page = 1) { xml &lt;- sprintf(&quot;%s/page/%i/&quot;, blog, page) %&gt;% read_html() items &lt;- xml_find_all(xml, &quot;.//article&quot;) xml_find_all(items, &quot;.//header/h2&quot;) %&gt;% xml_text() } #* @get /eoda_blog eoda_blog_ &lt;- function(last_page = 3) { lapply(1:last_page, eoda_blog) %&gt;% unlist() } #* @get /blog_that blog_that &lt;- function(count = 3) { rocket_science(eoda_blog_(), count = count, lang = &quot;de&quot;) } Run and test $ docker run -d -p 8011:8000 --name plumber \\ -v `pwd`/scripts:/endpoints crazycapivara/plumber r /endpoints/serve_that.R curl -s http://localhost:8011/blog_that?count=4 | jq Use in other apps # app.py from flask import Flask, render_template import requests api = &quot;http://plumber:8000/rstudio_news&quot; def get_news(): response = requests.get(api) data = response.json() response.close() return data app = Flask(__name__) @app.route(&quot;/&quot;) def hello(): return render_template(&quot;rstudio_news.html&quot;, news = get_news()) if __name__ == &quot;__main__&quot;: app.run(host = &quot;0.0.0.0&quot;, debug = True) # docker-compose.yml version: &quot;2&quot; services: plumber: image: crazycapivara/plumber:rstudio_news flask: image: crazycapivara/flask command: app.py ports: - &quot;5005:5000&quot; "],
["cran-stats-with-metabase-and-mongodb.html", "CRAN stats with metabase and mongodb", " CRAN stats with metabase and mongodb Dockerfile FROM rocker/rstudio LABEL maintainer=&quot;&lt;crazycapivara@gmail.com&gt;&quot; RUN apt-get update \\ &amp;&amp; apt-get install -y libssl-dev libsasl2-dev RUN install2.r mongolite remotes httr \\ &amp;&amp; installGithub.r metacran/cranlogs COPY ./scripts /home/rstudio/scripts Docker Compose version: &quot;2&quot; services: rstudio: build: . ports: - &quot;8787:8787&quot; metabase: image: metabase/metabase ports: - &quot;3015:3000&quot; mongodb: image: mongo ports: - &quot;27020:27017&quot; Script # dl_stats.R library(cranlogs) library(mongolite) argv &lt;- commandArgs(TRUE) # get logs cat(&quot;Fetch logs\\n&quot;) pkgs &lt;- c(&quot;shiny&quot;, &quot;shinydashboard&quot;, &quot;rmarkdown&quot;, &quot;leaflet&quot;) if(!is.na(argv[1])) { pkgs &lt;- argv[1] } print(pkgs) logs &lt;- cran_downloads(pkgs, when = &quot;last-month&quot;) print(tail(logs)) # write logs to db db &lt;- &quot;rstudio&quot; collection &lt;- &quot;cranlogs&quot; cat(&quot;insert data\\n&quot;) conn &lt;- mongo(collection, db = db, url=&quot;mongodb://mongodb&quot;) eat_msg &lt;- conn$insert(logs) cat(&quot;done\\n&quot;) Add data $ docker run -it --rm -v `pwd`/scripts:/scripts \\ --network futurama crazycapivara/rstudio Rscript /scripts/dl_stats.R ggplot "],
["bookdown.html", "bookdown", " bookdown Dockerfile FROM rocker/r-base LABEL maintainer=&quot;&lt;crazycapivara@gmail.com&gt;&quot; RUN install2.r rmarkdown formatR bookdown COPY ./book /book WORKDIR /book RUN apt-get update &amp;&amp; apt-get install pandoc -y \\ &amp;&amp; rm -rf /var/lib/apt/lists/* Render book # render_book.R library(bookdown) render_book(&quot;.&quot;) $ docker run -t --rm \\ -v `pwd`/book:/book \\ crazycapivara/r-base-bookdown r render_book.R Serve book # docker-compose.yml version: &quot;2&quot; services: nginx: image: nginx:alpine ports: - &quot;8080:80&quot; volumes: - ./book/_book:/usr/share/nginx/html:ro "],
["shinyproxy.html", "ShinyProxy", " ShinyProxy https://www.shinyproxy.io Runs on the host # Dockerfile FROM openanalytics/r-base ... EXPOSE 3838 CMD [&quot;R&quot;, &quot;-e shiny::runApp(&#39;/root/euler&#39;)&quot;] docker build -t openanalytics/shinyproxy-template # application.yml apps: - name: euler display-name: Euler&#39;s number docker-cmd: [&quot;R&quot;, &quot;-e shiny::runApp(&#39;/root/euler&#39;)&quot;] docker-image: openanalytics/shinyproxy-template groups: scientists java -jar shinyproxy-1.0.1.jar "],
["continious-integration.html", "Continious Integration", " Continious Integration Gitlab Drone Concourse … "],
["gitlab-ci.html", "Gitlab CI", " Gitlab CI https://about.gitlab.com All in one Requirements: 4GB min Gitlab Container # docker-compose.yml version: &quot;2&quot; services: gitlab: image: &quot;gitlab/gitlab-ce:latest&quot; restart: always hostname: &quot;172.17.0.1&quot; environment: GITLAB_OMNIBUS_CONFIG: | external_url &quot;http://172.17.0.1:9090&quot; gitlab_rails[&quot;gitlab_shell_ssh_port&quot;] = 2224 ports: - &quot;9090:9090&quot; - &quot;2224:22&quot; volumes: - &quot;./config:/etc/gitlab&quot; - &quot;./logs:/var/log/gitlab&quot; - &quot;./data:/var/opt/gitlab&quot; Gitlab runner Start runner #!/bin/sh docker run -d --name gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v `pwd`/gitlab-runner/config:/etc/gitlab-runner \\ gitlab/gitlab-runner:latest Register runner $ docker exec -it gitlab-runner gitlab-runner register Config # config.toml [[runners]] name = &quot;bender&quot; url = &quot;http://&quot;172.17.0.1:9090/&quot; token = &quot;3bd3d65fd0fe66bcece672a2eb7603&quot; executor = &quot;docker&quot; [runners.docker] tls_verify = false image = &quot;rocker/r-base&quot; privileged = false disable_cache = false volumes = [&quot;/www/data_science:/share_that&quot;, &quot;/cache&quot;] shm_size = 0 pull_policy = &quot;never&quot; [runners.cache] Pipeline # .gitlab-ci.yml stages: - julia - r - deploy julia: stage: julia image: julia artifacts: paths: - that.csv expire_in: 5 minutes script: - julia create_csv.jl r: stage: r image: rocker/r-base script: - Rscript -e &quot;df &lt;- read.csv(&#39;that.csv&#39;); do_science(df)&quot; deploy: stage: deploy image: alpine script: - cp that.csv /www/public "],
["drone.html", "Drone", " Drone https://drone.io Lightweight Local builds via drone CLI (runs containers on the local host) Integrations: Gogs GitLab Github Bitbucket Gitea Gogs container # start gogs $ docker run --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs Drone server and agent # docker-compose.yml version: &#39;2&#39; services: drone-server: image: drone/drone:0.7 ports: - 80:8000 volumes: - /var/lib/drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=true - DRONE_HOST=${DRONE_HOST} #- DRONE_GITHUB=true #- DRONE_GITHUB_CLIENT=${DRONE_GITHUB_CLIENT} #- DRONE_GITHUB_SECRET=${DRONE_GITHUB_SECRET} - DRONE_GOGS=true - DRONE_GOGS_URL=http://gogs.mycompany.com drone-agent: image: drone/drone:0.7 command: agent restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=${DRONE_SECRET} Pipeline # .drone.yml pipeline: rocket: image: rocker/rstudio commands: - install2.r magrittr - Rscript -e &quot;library(magrittr); iris %&gt;% head() %&gt;% print(); write.csv(iris, &#39;that.csv&#39;)&quot; science: image: rocker/rstudio commands: - cat that.csv deploy: image: alpine commands: - echo This is rocket science - cp that.csv /inside - rm that.csv volumes: - /tmp:/inside when: status: success Run local build # Install drone CLI $ curl -L https://github.com/drone/drone-cli/releases/download/v0.8.0/drone_linux_amd64.tar.gz | tar zx $ install -t /usr/local/bin drone # Run task $ drone exec .drone.yml "],
["concourse.html", "Concourse", " Concourse http://www.concourse.ci Lightweight local builds/tasks via fly (runs containers on the server) Docker compose Version: &#39;3&#39; services: concourse-db: image: postgres:9.5 environment: POSTGRES_DB: concourse POSTGRES_USER: concourse POSTGRES_PASSWORD: changeme PGDATA: /database concourse-web: image: concourse/concourse links: [concourse-db] command: web depends_on: [concourse-db] ports: [&quot;8080:8080&quot;] volumes: [&quot;./keys/web:/concourse-keys&quot;] restart: unless-stopped # required so that it retries until conocurse-db comes up environment: CONCOURSE_BASIC_AUTH_USERNAME: concourse CONCOURSE_BASIC_AUTH_PASSWORD: changeme CONCOURSE_EXTERNAL_URL: &quot;${CONCOURSE_EXTERNAL_URL}&quot; CONCOURSE_POSTGRES_HOST: concourse-db CONCOURSE_POSTGRES_USER: concourse CONCOURSE_POSTGRES_PASSWORD: changeme CONCOURSE_POSTGRES_DATABASE: concourse concourse-worker: image: concourse/concourse privileged: true links: [concourse-web] depends_on: [concourse-web] command: worker volumes: [&quot;./keys/worker:/concourse-keys&quot;] environment: CONCOURSE_TSA_HOST: concourse-web Tasks # task.yml platform: linux image_resource: type: docker-image source: repository: rocker/r-base inputs: - name: bender run: path: ./bender/build.sh # build.sh #!/bin/sh set -e -x install2.r magrittr Rscript -e &quot;library(magrittr);iris %&gt;% head() %&gt;% print()&quot; Submitting local task $ fly -t example execute -c ci/task.yml "],
["orchestrierung.html", "Orchestrierung", " Orchestrierung Docker Swarm https://docker.com Kubernetes https://kubernetes.io Rancher http://rancher.com … "],
["docker-swarm.html", "Docker Swarm", " Docker Swarm Seit Version 1.12 bietet Docker eine integrierte Cluster-Implementierung an. $ docker swarm $ docker node $ docker service # Create a manager (node) $ docker swarm init --advertise-addr 192.168.99.100 # Generate token needed to join manager $ docker swarm join-token worker # Add a worker (node) $ docker swarm join --token [...] 192.168.99.100:2377 # List nodes $ docker node ls # Deploy a service $ docker service create --replicas 1 --name helloworld alpine ping docker.com "],
["rancher.html", "Rancher", " Rancher Features Web-GUI can manage Docker Swarm Kubernetes Installation ## Management node (server) $ docker run -d --restart=unless-stopped -p 8080:8080 rancher/server ## Add workers (agents) $ docker run -d [...] rancher/agent [...]token Browse Web-GUI http://localhost:8080 "],
["kubernetes-google.html", "Kubernetes (Google)", " Kubernetes (Google) Check https://kubernetes.io "],
["portainer.html", "Portainer", " Portainer https://portainer.io Portainer is an open-source lightweight management UI which allows you to easily manage your Docker hosts or Swarm clusters $ docker volume create portainer_data $ docker run -d -p 9000:9000 \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v portainer_data:/data portainer/portainer You can also manage swarm clusters with portainer https://portainer.io/install.html "],
["more-container-runtime-engines.html", "More container runtime engines?", " More container runtime engines? http://cri-o.io RedHat Lightweight Container Runtime for Kubernetes https://coreos.com/rkt CoreOS … rkt also plays a central role in how Google Container Image and CoreOS Container Linux run Kubernetes. … "],
["hey-ho.html", "Hey ho", " Hey ho So long, and thanx for all the fish. Stefan Kuethe crazycapivara@gmail.com Github: https://github.com/crazycapivara Dockerhub: https://hub.docker.com/r/crazycapivara "]
]
